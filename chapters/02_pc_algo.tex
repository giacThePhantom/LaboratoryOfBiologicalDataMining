\chapter{PC algorithm}

\section{Estimating high-dimensional directed acyclic graphs with the PC-algorithm}

	\subsection{Introduction}
	Graphical models are a popular probabilistic tool to analyse and visualize conditional independence relationships between random variables.
	The major building blocks of these models are nodes (the random variables) and edges (conditional dependence).
	The structure of conditional independence among the random variables can be explored using the Markov properties.
	The estimation of a DAG from data is difficult due to the enormous size of the space of DAGs.
	The PC-algorithm is an alternative to greedy or structurally restricted approaches.
	It starts from a complete, undirected graph and deletes recursively edges based on conditional independence decisions.
	This yields an undirected graph that can be partially directed and further extended to represent the underlying DAG.
	This algorithm runs in the worst case in exponential time, but if the true underlying DAG is sparse, it is reduced to a polynomial runtime.
	Here there is a focus on estimating the equivalence class and the skeleton of DAGs corresopnding to multivariate Gaussian distributions in high-dimensional context, or where the number of nodes $p$ may be much larger than the sample size $n$.

	\subsection{Finding the equivalence class of a DAG}
	Let $G=(V,E)$ a graph.
	The set of vertices $V$ corresponds to the components of a random vector $\vec{X}\in\mathbb{R}^p$.
	A probability distribution $P$ on $\mathbb{R}^p$ is said to be faithful with respect to $G$ if conditional independences of the distribution can be inferred from $d$-separation in $G$.
	Consider a random vector $\vec{X}\sim P$.
	Faithfulness of $P$ with respect to $G$ means that for any $i,j\in V$ with $i\neq j$ and any set $s\subseteq V$:

	$$\vec{X}^{(i)}\land \vec{X}^{(j)}\text{ are conditionally independent given } \{\vec{X}^{(r)}|r\in s\}\Leftrightarrow i\land y \text{ are d-separated by } s$$

	Faithfulness is ruling out some classes of probability distributions.
	The skeleton of a $DAG$ is the undirected graph obtained from $G$ by substituting undirected edges for directed ones.
	A $v$-structure in a DAG is an ordered triple of node such that $(i,j)\in G\land (k,j)\in G\land (i,k)\not\in G$.
	Two DAGs are equivalent is and only is they have the same skeleton and v-structures.
	If $P$ is faithful with respect to a DAG $G$ there is an edge between node $i$ and $j$ in the skeleton of DAG $G$ is and only if $\forall s\subseteq V\backslash\{i,j\}, \vec{X}^{(i)}\land \vec{X}^{(j)}$ are conditionally dependent given $\{\vec{X}^{(r)},r\in s\}$.
	If $P$ is faithful with respect to a DAG $G$ the skeleton of the DAG is a subset to the conditional independence graph corresponding to $P$.
	Every edge in the skeleton indicates some strong dependence which cannot be explained by accounting for other variables.

		\subsubsection{PC-algorithm for finding the skeleton}
		The PC-algorithm betters from a naive strategies that checks for conditional independences given all subsets.
		For the variance PC-stable of this algorithm the deletion of the arc is postponed to the change of $l$ so the result does not depend on the order of the variables and it is parallelizable.

			\paragraph{Population version}
			In the population version of the PC-algorithm perfect knowledge about all necessary conditional independence relations is assumed available.

			\input{chapters/02/01_pc_pop_algorithm}

			The maximal value of $l$ is denoted $m_{reach}$ and depends on the underlying distribution.
			Considering a DAG $G$ and assume that the distribution $P$ is faithful to $G$.
			Denote the maximal number of neighbours by $q = \max\limits_{1\le j\le p}|adj(G,j)|$.
			Then the $PC_{pop}$ algorithm construct the true skeleton of the DAG.
			Moreover $m_{reach}\in\{q-1,q\}$.

			\paragraph{Sample version}
			For finite sample there is a need to estimate conditional independencies.
			Assuming faithful models (conditional independence relations correspond to d-separations) in the Gaussian case conditional independences can be inferred from partial correlations.
			Assume that distribution $P$ of the random vector $\vec{X}$ is a multivariate normal.
			For $i\neq\in\{1,\dots,p\}, k\subseteq\{1,\dots, p\}\backslash\{i,j\}$, denote $\rho_{i,j|k}$ the partial correlation between $\vec{X}^{(i)}$ and $\vec{X}^{(j)}$ given $\{\vec{X}^{(r)}, r\in k\}$ then $\rho_{i,j|k} = 0$ if and only if $\vec{X}^{(i)}$ and $\vec{X}^{(j)}$ are conditionally independent given $\{\vec{X}^{(r)}, r\in k\}$.
			The partial correlations can be estimated and the sample partial correlation $\hat{\rho}_{i,j|k}$ can be calculated, for some $h\in k$:

			$$\rho_{i,j|k} = \frac{\rho_{i,j|k\backslash h}-\rho_{i,h|k\backslash h}\rho_{j,h|k\backslash h}}{\sqrt{(1-\rho^2_{i,h|k\backslash h})(1-\rho^2_{j,h|k\backslash h})}}$$

			For testing whether a partial correlation is zero or not Fisher's z-transform is applied:

			$$Z(i,j|k) = \frac{1}{2} \log(\frac{1=\hat{\rho}_{i,j|k}}{1-\hat{\rho}_{i,j|k}})$$

			The null hypothesis is rejected $H_o(i,j|k):\rho_{i,j|k} = 0$ against the two sided alternative $H_A(i,j|K): \rho_{i,j|k} \neq 0$ if $\sqrt{n-|k|-3}Z(i,j|k)>\Phi^{-1}(1-\frac{\alpha}{2})$, where $\Phi$ denotes the cdf of $\mathcal{N}(0,1)$.
			The sample version of the PC-algorithm is the same of the population version, with the if statement replaced by $\sqrt{n-|k|-3}Z(i,j|k)>\Phi^{-1}(1-\frac{\alpha}{2})$.
			This algorithm yields a data-dependent $\hat{m}_{reach,n}$.
			The only tuning parameter is $\alpha$, the significance level for testing partial correlations.
			This algorithm is asymptotically consistent even if $p$ is much larger than $n$ but the DAG is sparse.
			For the gene\@home project, linear correlations between genes are computed using the Pearson coefficient:

			$$r = \frac{\sum\limits_{i=1}^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sqrt{\sum\limits_{i=1}^n(X_i-\bar{X})^2}\sqrt{\sum\limits_{i=1}^n(Y_i-\bar{Y})^2}}$$

		\subsubsection{Extending the skeleton to the equivalence class}
		While finding the skeleton the separations sets that made edges drop out were recorded by $S$.
		This is essential for extending the skeleton to the equivalence class.

			\input{chapters/02/02_extension_to_CPDAG}

\section{A computing system for discovering causal relationships among human genes to improve drug repositioning}
The gene\@home project aims to expand gene networks using transcriptomic datasets.
For human data the objective is to provide a public resource to navigate and combine results by expanding each single human transcript.
The platform hosted the NE$S^2$RA algorithm.
Starting from a local gene network LGN based on previous biological knowledge, its expansion consists in a set of genes and a list of interactions which describe putative causal relationships with the genes in the LGN.
The expansion is calculated on observational gene expression data organized in a coherent normalized data matrix.
To overcome the problem of unique elaborations OneGenE has been developed.
The list of gene expansions is calculated for each gene in an organism by systematically running single-gene NE$S^2$RA expansions with fixed parameters and then combine them afterwards to simulate LGN expansions.
The expansions of the gene networks is based on the transcriptomic dataset provided by the FANTOM project.
Their data comes from sequencing of RNA extracted from different samples of human tissues and cell lines and contains expression profiles of $201802$ gene isoforms.
Drug repositioning is an alternative approach for the discovery of new therapeutic opportunities for already approved medicines.
This method, which relies on previous knowledge, speeds up the approval procedure of the drug regulators and can represent a valuable approach.

	\subsection{Method}
	OneGenE is a method to compute ranked candidate gene lists that expands known local gene networks given gene expression data.
	It is based on the systematic and iterative application of the skeleton function of the PC algorithm on subsets of the input data.
	Candidate expansion lists are pre-computed for each gene of the target organism.
	Secondly a set of transcript of interest LGN is provided as input and the intermediate results are aggregated.

	\input{chapters/02/03_pre_one_gene}
		\subsubsection{Data and input}
		The algorithm starts with an $n\times m$ gene expression data matrix $E$, where $n=|S|$ is the number of transcripts $S$ and $m$ is the number of samples and a set of parametertuples $\Theta = \{\theta\} = \{(\alpha, d, i)|\alpha\in A, d\in D, i\in I\}$ where $A$, $D$ and $I$ are the sets of alpha values, tile sizes and the number of iterations.

		\subsubsection{Nested loop}
		For each transcript $g$ in $S$, $p$ instances of PC-IM are executed, where $p=|\Theta| = |A||D||I|$.
		The internal loop receive as input a single gene $g$ with probability vbector $\Pi = 1$.
		The internal loop comprises the subsetting of the transcripts, the run of PC-skeleton on each subset and the computation of absolute frequencies, relative frequencies and the corresponding order of the candidates list.6

		\subsubsection{Pre-computation result}
		In OneGenE the ranking aggregation is postponed.
		Each PC-IM returns a candidate expansion list $l_{g,\theta}$ for each tuple of parameters corresponding to the set of lists resulting from the algorithm.
		The candidate lists are stored and the data is ready to be queried.

		\subsubsection{Ranking or list aggregation}
		Let $S_{LGN}$ be the set of transcripts in an input LGN and $l_{g,\theta}$ the candidate expansion list of $g$ with parameters $\theta$.
		The final candidate expansion list is obtained combining $\mathcal{L} = \{l_{g,\theta}| g\in S_{LGN}, \theta\in\Theta\}$ by means of a ranking aggregator.
		High relative frequency provides evidence of a putative direct causal relationship.
		Ranks are instead useful for comparing list and prioritization.

		\input{chapters/02/04_agg_one_gene}

	\subsubsection{Data and running paramters}
	The human transcriptome data have been obtained from the FANTOM5 project.
	It was generated using single molecule CAGE or cap analysis gene expressione.
	Normalized expression values are extimated as transcripts per milion TPM.
	The data has been filtered removing unknown transcripts and with absent or low expression values among almost all samples.
	The single gene NE$S^2$RA expansion where submitted with a tile size of $1000$, $1000$ iterations and $\alpha=0.05$.

	\subsection{Validation}
	To evaluate the biological pertinence of the single-gene NE$S^2$RA expansion obtained by OneGenE where used gene expansions involving genes of medical relevance for neural motor dideases and hematopoietic tumors.
	For each expansion, the top scoring $250$ transcripts where considered.
	OneGenE expansions where benchmarked against a simple Pearson correlation analysis.
	Starting from the same seed transcript, the top $250$ correlated transcripts were considered and compared to the $250$ transcripts identified by OneGenE.
	To quantify the overlap among the expansions obtained from the same transcript the Jaccard index was calculated: the number of items shared between the two sets divided by the total number of items in both sets.
	OneGenE expansions are largely pppulated by distinct genes with respect to the correlation approach.
	To evaluate the biological pertinence, a functional enrichment was performed and the single-gene expansions consistently achieves higher biological pertinence than the correlation approach using the fraction of pertinent enrichments.
	Lastly using known protein-protein interaction in STRING, for each of the expansion the list of gene was compared with the list of interactions in STRING.
	Based on the overlap between the genes and annotated interactions odds ratio values were calculated with outstanding results.

	\subsection{Prostate cancer}
	$22$ genes expanded as single-gene by NE$S^2$RA on two transcriptomic datasets.
	First analyse direct interactions within input genes and represent as graphs.
	Focusing on two networks and aggregating  the expansion list og the genes belonging to it.
	A comparison with STRING and functional enrichment analyses allowed to understand nature and composition of those networks.
	After filtering genes alredy known to be related to prostate cancer, query against Gene Drug interaction database identified novel targets for this disease that can support drug repositioning.
	The functional relationship between the input genes obtained is studied by their mutual interaction: the pair $(x,y)$ of input genes is defined as the presence of gene $x$ into the expansion list of $y$ and viceversa.
	After a comparison with STRING functional involvement of the networks and the gene composition enrichment analyses with KEGG pathways and gene anthology biological process categories.
	Finally after filtering the networks for genes already known DGIbd database of gene-drug interaction was queried and retrieved some drugs involved.
	After that target that may be cytotoxic where removed.

	\subsection{Coronary artery disease}
	The OneGenE approach was used to identify novel putative drug target for coronary artery disease CAD, considering genes genetically associated with it.
	The list of those genes has been obtained from open targets.
	In order to retain the genes most related the expansions list where trimmed containing only the first $N_l=\max\{5, 1-R_l+1\}$, where $R_l$ is the rank based on genetic association derived from open targets.
	The lists of isoforms were aggregated summing the relative frequencies computed by NE$S^2$RA.
	Then the list of isoforms was ranked and converted into a ranked list of genes.
	ToppGene was used to perform enrichment analysis against the biological processes of the gene ontology.
	To quantify the overlap between the ranked list og genes genetically associated with CAD and the ranked expansion lists obtained from NE$S^2$RA, they used the weighted jaccard similarity: $WJS(\rho, \sigma) = \frac{\sum\limits_{i=1}^n\min(\rho_i, \sigma_i)}{\sum\limits_{i=1}^n\max(\rho_i, \sigma_i)}$, where $\rho_i$ and $\sigma_i$ are the weights corresponding to the same item $i$, the weight of a feature $i$ in a ranked list $\rho$ is computed as $len(\rho)-rank(i)+1$.
	These scores depend on the length of the list, so they are not comparable.
	To make them comparable a permutation approach was used to estimate a set of score distributions.
	For each length $2000$ random list of genes were generated and the WJS was computed and the score distribution associated to that length generated.
	Then these distributions where used to compute empirical p-values for multiple hypothesis testing.

\section{NESRA}
Before gene\@home the scientific pipeline consisted of:

\begin{multicols}{2}
	\begin{itemize}
		\item Organism choice.
		\item Finding a suitable gene expression dataset.
		\item Dataset filtering and imputing.
		\item Choose target LGN.
		\item PC-IM parameters test.
	\end{itemize}
\end{multicols}

NESRA is a network expansion by variable subsetting and ranking aggregation.
It systematically and iteratively apply subsetting varying parameters and the list is then aggregated.

\input{chapters/02/05_nesra}

Its successor NE$S^2$RA models, using a probability vector, the confidence of the presence of the genes belonging to the local gene network.
NES$S^2$RA or network expansion by stratified subsetting and ranking aggregation tries to solve the problem of finding candidates for gene expansion.
It alllows to model with a probability the presence of the genes of the network to be expanded in the subset and the sampling is stratified.
It is based on the PC-algorithm.

	\subsection{Gene network expansion}
	Given a set $S$ of gene transcripts whose level of expression has been measured $p$ times in different conditions, such that for reach $s_i\in S$ there is a vector $x_i\in\mathbb{R}^p$ of exression levels.
	Let us assume that there exists a generally unknown ground truth direct graph $G=(S,B)$ wich represents the real causal relationships between the gene transcripts.
	The discovery of candidate genes for GNE is defined as follows.
	Given a graph $G=(N,B)$ where $N\subseteq S$ and $B\subseteq N\times N$, find a ranked list of elements of $S\backslash N$ such that the elements of the list are connected or very near to the elements of $N$ in $G$.

	\subsection{NE$S^2$RA}
	This algorithm as input data the LGN and the probability of each gene of the LGN to be included in the subsets, the set of parameters to be used and the gene expression levels for the considered organisms.
	The inclusion of the LGN in the subsetting step improves the quality of the result because the composition of each subset is influenced by the LGN nodes added.
	The vector of probability is the representation of the knowledge of the user about the presence of specific genes in the network.
	Depending on the probabilities genes will be included in the data for the run of the PC-algorithm.

		\subsubsection{Ranking procedure}
		The ranking procedure contains three steps which create the subsets, execute several calls of the skeleton of the PC-algorithm and compute the transcripts frequency that defines the order of each ranking.
		The RP takes as parameters the number of iterations, de dimension of the subset, the significance level for the skeleton and the probability vector.
		The output depends on the order of the inputs, mitigated by the different iterations.
		This procedure returns a ranked list of $k$ elements.

		\input{chapters/02/06_nesra_rp}

		\subsubsection{Subsetting}
		A subsetting operation is done systematically and iteratively on the whole data set in order to randomly select genes that will be processed by the skeleton PC.
		It is controlled by iteration and subset size parameters.
		The subsetting is stratified and genes of the LGN can have increased probability of beein in the subsets.
		For a given pair of subset a first selection controlled by the probability vector, specifies which genes of the LGN are present in it.
		The one not selected in the first are considered in the second with uniform probability and then there is a third selection restricted to genes not already present.
		The probability vector is such that the ith component $\pi_i$ modulates the probability of the precence of the ith gene $g_i$ in the subsets.

		\subsubsection{Aggregation}
		For each pair subset size and iteration NE$S^2$RA executes a number of skeleton procedures.
		This yields list of genes, which are combined ranked by their number of appearances.
		The list of candidate genes is produced applying different ranking aggregation methods on the ranked lists using the number of appearances, Borda Count and MC4 heuristic.
		The number of appearances counts how many rankings a certain genes has.
		The Borda Count consists of constructing a matrix $A(m,n)$ with $m$ rows and $n$ columns, corresponding to the genes and the rankings.
		The element $a_{ij}$ is the rank of gene $i$ on ranking $j$ and a statistic for each gene is computed on the rows of the matrix.
		The two statistics are the BC-mean and BC-min.
		The MC4 heuristic is an aggregator based on Markov chains.
		It computes the transition matrix of the pairwise comparison of all the rankings for each gene.
		A step in the Markov chain assigns a higher probability to a gene $q$ is $rank(q)< rank(p)$ for a majority of the lists that ranked both.
		The steady state assigns higher probability to the genes with higher ranks.

			\paragraph{OneGenE}
			In OneGenE this step is postponed when there is a query.
			Let $S_{LGN}$ be the set o transcript in an input LGN and $l_{g, \theta}$ the candidate expansion list of the gene $g$ with parameter tuple $\theta$.
			The final candidate gene expansion list is obtained combining the set of partial result: $\mathcal{L} = \{l_{g, \theta} | g\in S_{LGN}, \theta\in \Theta\}$ by means of a ranking aggregator.
			Given the set of ranked list the ranking aggregation problem is combining the ranking in it in order to obtain a better final ordering $l^*$.

				\subparagraph{Borda Count}
				It associates to each element $u$ in a list $l$ a Borda score $B_l(u)$.
				The final rank of the element $u$ will be computed using an aggregation function: $f(B_1(u), \dots, B_n(u))$.
				Common aggregation functions are the arithmetic mean or the median.

				\subparagraph{RnakAggreg Package}
				This algorithm uses local search trying to find $l^* = \arg\min\limits_l\biggl( \sum\limits_{i = 1}^{|\mathcal{L}|} w_i d(l,l_i)\biggr)$
				Where $w_i$ is the weight associated with list $l_i$ and $d$ is the Kendall Tau or Spearmann distance.

				\subparagraph{RobustRankAggreg package}
				It is an aggregator based on order statistics.
				The assumption is that the rank of each element $u$ in lists in $S$ is sampled from a distribution and, once it is known, it can be compared with a null distribution obtained by sampling the ranking uniformly.
				The aggregator associates at each element a corrected p-value and the final ranking is obtained sorting the elements by p-value.

				\subparagraph{Markov chain method}
				Markov chain 4 method builds an ergodic Markov chain where each state represents a ranked element using the ranking in $\mathcal{L}$.
				It is build starting from $u$ and an element $v$ is sampled uniformly.
				If $v$ is ranked lower for a majority of the lists where both elements are present, it associates a probability of staying in $u$.
				The final rank is obtained computing the stationary distribution of the chain and sorting the element by their stationary probability.
